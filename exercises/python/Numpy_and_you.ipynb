{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python is for science!\n",
    "\n",
    "There are many cool libraries available to you in Python. These include `numpy` and `matplotlib` (used in this notebook) and scipy. `numpy`, which accesses very fast compiled code, is particularly good for numerical computing, `matplotlib` allows the quick production of visually appealing and useful plots (many of the plots you will see nowadays are produced with matplotlib), and `scipy` contains an array of scientific functionality. All of these are installed on the Docker container you downloaded and you will see them in use in the workshops this week.\n",
    "\n",
    "In this notebook, we aren't hoping to preempt the other sessions, but will proceed through some useful tasks you might wish to do from time to time, demonstrating reading from `PSRFITS` files, inspecting the header, putting the binary data into a numpy array, plotting a dynamic spectrum and then manipulating the plot to enhance clarity of the displayed output. The file in question is in the same directory as this notebook; it's a small file (already subbanded) of a bright pulsar, taken at Arecibo Observatory with `puppi`, in search mode.\n",
    "\n",
    "Examples here are from Michael Lam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import statements\n",
    "\n",
    "Here we import the useful stuff. `numpy` is nearly always aliased as `np` and `astropy.io.fits` is often aliased as `pyfits` because `pyfits` is an older package, used in a lot of legacy code, that was rolled into `astropy`'s `astropy.io.fits` module (using this alias means that a lot of that old code still works!). The `cm` module in `matplotlib` is for colormaps, and the `pyplot` provides us with a plotting functionality similar to that in `MATLAB`. Lastly, the `%matplotlib inline` directive, which is specific to `Jupyter`, lets us plot inside the notebook cells rather than popping up a fresh window for each plot.\n",
    "\n",
    "It's really very impressive, how much cool functionality is given to use by just importing those few modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import astropy.io.fits as pyfits\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do you have the file?\n",
    "\n",
    "We use a Jupyter directive to get a list of the files in the current working directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `puppi_57166_J1404+12_1326_subs_0001.fits` isn't in there, you need to get it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://ipta.phys.wvu.edu/files/student-week-2018/puppi_57166_J1404+12_1326_subs_0001.fits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the fits file via astropy\n",
    "\n",
    "Sometimes PSRFITS files are missing the END card so we set `ignore_missing_end = True` just in case. This is something which can save you frustrating errors, particularly when running a pipeline on very many files. The file is in the same directory as this notebook; as mentioned above, it's a subbanded search-mode file of a bright pulsar; the period of this pulsar, `J1404+12`, is around ~2.65 seconds and the DM is 18.836.\n",
    "\n",
    "You can read the `astropy.io.fits` documentation, with examples, [at this page](http://docs.astropy.org/en/stable/io/fits/) (where you also see how to use it if you aren't aliasing to `pyfits`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Should include full filepath if it's not in the local directory\n",
    "filename = \"puppi_57166_J1404+12_1326_subs_0001.fits\"\n",
    "#the open function returns a list of the Header/Data Units (HDUs) in the file\n",
    "hdulist = pyfits.open(filename,ignore_missing_end=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the data shape\n",
    "\n",
    "Sometimes you don't know what to expect, so this is how you can see what's in the FITS file. The first HDU is the `PRIMARY` HDU. The basic FITS standard is explained briefly [here](https://fits.gsfc.nasa.gov/fits_primer.html), but PSRFITS is an extension of this (and in some cases, the data values are encoded with less than 8 bits and packed into 8 bit `ints`, which means they need to be unpacked; this file, however, contains 8-bit values). Here we learn that there are two HDUs and get information about their contents.\n",
    "\n",
    "The first thing you'll want to try to understand the structure of a FITS file is to use the `info()` function, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show useful information about the tables in the FITS file\n",
    "hdulist.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the names of the different tables; in this case there are two, `PRIMARY` and `SUBINT`, which you can either call by name like `hdulist['PRIMARY']` or number like `hdulist[0]`. There is always a primary header and then there can be multiple tables stores.\n",
    "\n",
    "For any of the tables, you can use `TABLE.header` to grab header information. The header for `PRIMARY` is \"the\" header for the FITS file but tables can store their own headers. Let's look at the primary header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the header in the primary HDU: typically the observation parameters are in here\n",
    "hdulist['PRIMARY'].header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where is my data?\n",
    "\n",
    "The data are in the `SUBINT` HDU. Let's first look at the header. You can see that there's a lot of different fields of information, what the shapes/formats of the data are, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdulist['SUBINT'].header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any table with data, you can use `TABLE.data` to grab the data. Let's look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the data\n",
    "data = hdulist['SUBINT'].data\n",
    "# Look at the first subintegration\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can try to match what's in the header to what's in the data table. You'll notice that the last element of this first subintegration is the full data array of pulse intensities. Before that are a bunch of other items that you can see in the header, such as the length of the subintegration (in units of seconds, note TUNIT1), the RA/dec position of the telescope, etc. Let's explicitly grab the length of the subintegration using the flag indicated in the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdulist['SUBINT'].data['TSUBINT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, each of the 68 subintegrations has 2.684 seconds worth of data. \n",
    "\n",
    "Now let's look at the shape of the intensity data. These shapes can be derived from the header as well but sometimes you'll just want to grab these in code rather than just printing them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of subintegrations\n",
    "print(np.shape(data))\n",
    "# shape of each subintegration (the last value is the actual array of intensities)\n",
    "# shape is in (time, polarization, frequency, phase)\n",
    "print(np.shape(data[0][-1]))\n",
    "# Remove the dimensions with only one value, which makes a dynamic spectrum in (time, frequency)\n",
    "print(np.shape(data[0][-1].squeeze()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are 68 subintegrations, each with about 2.684 seconds of data. In each of these subintegrations, there are 32768 time samples, 1 polarization, 128 frequency channels, and 1 phase bin. Note that since this is a search-mode observation rather than a fold-mode observation, there's no pulse period and so no phase!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the dynamic spectrum of the first subintegration\n",
    "\n",
    "The dynamic spectrum shows the intensities as a function of time and frequency. Given the shape of the squeezed array above, that's very easy to do in matplotlib with the `imshow()` function. For convenience, we've added some useful arguments to the function. You can also pick your own [colormap](https://matplotlib.org/2.0.2/examples/color/colormaps_reference.html)!\n",
    "\n",
    "Side programming note: because you should think of a 2D array with indices as (row, column), which is like (y,x), to plot in (x,y), you'll often want to transpose the array as we have done below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynspec = data[0][-1].squeeze()\n",
    "# Transpose the array to go from (row, column) -> (x,y)\n",
    "plt.imshow(np.transpose(dynspec),origin='lower',interpolation='nearest',aspect='auto',cmap=cm.inferno)\n",
    "plt.xlabel('Time Bin')\n",
    "plt.ylabel('Frequency Channel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reduce the array in time\n",
    "\n",
    "The following is a simple function to average a 2D array in the first dimension (time in this case) by a certain factor. Then we will plot the reduced dynamic spectrum like above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def timeaverager(array,window_len):\n",
    "    if window_len==1:\n",
    "        return array\n",
    "    T,F = np.shape(array)\n",
    "    retval = np.zeros((T//window_len,F)) #integer division in python 3!\n",
    "    counts = np.zeros_like(retval)\n",
    "    for i in range(window_len):\n",
    "        retval += array[i:T:window_len,:]\n",
    "    return retval/window_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average down by a factor of 8 in time\n",
    "avgdynspec = timeaverager(dynspec,8)\n",
    "# Transpose the array to go from (row, column) -> (x,y)\n",
    "plt.imshow(np.transpose(avgdynspec),origin='lower',interpolation='nearest',aspect='auto',cmap=cm.inferno)\n",
    "plt.xlabel('Time Bin')\n",
    "plt.ylabel('Frequency Channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
